# LLaVA-Phi: Small Multi-Modal Assistant

**LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model** [[Paper](https://arxiv.org/pdf/2401.02330)] <br>


## Release
- [1/5] Our codes are currently undergoing internal review, will be release shortly (expecting next week).

## Acknowledgement
We build our project based on
- [LLaVA](https://github.com/haotian-liu/LLaVA): an amazing open-sourced project for vision language assistant
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory): We use this codebase to finetune Phi model
# llava-phi